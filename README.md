# Docuchat ğŸš€

A modern document knowledge chatbot built with **React**, **FastAPI**, **Pinecone** vector database, and **Google Gemini** LLM. Upload your documents and ask questions about them using RAG (Retrieval Augmented Generation).

## âœ¨ Features

- ğŸ¤– **Powered by Google Gemini** for natural language understanding
- ğŸ“Š **Pinecone vector database** for efficient similarity search
- âš›ï¸ **React frontend** with modern UI/UX
- ğŸš€ **FastAPI backend** with RESTful API
- ğŸ³ **Docker-based** deployment with Docker Compose
- ğŸ’¬ **Conversational memory** for context-aware responses
- ğŸ“„ **Multi-format support**: PDF, DOCX, TXT files
- ğŸ” **Semantic search** over your document knowledge base

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  FastAPI Backendâ”‚
â”‚   (Port 3000)   â”‚  REST   â”‚   (Port 8000)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   API   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                â–¼                â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Pinecone â”‚    â”‚  Gemini  â”‚    â”‚ Sentence â”‚
              â”‚  Vector  â”‚    â”‚   LLM    â”‚    â”‚Transformersâ”‚
              â”‚   Store  â”‚    â”‚          â”‚    â”‚ Embeddings â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- **Docker** and **Docker Compose** installed
- **Pinecone API key** (sign up at https://www.pinecone.io/)
- **Google API key** for Gemini (get it from https://makersuite.google.com/app/apikey)

## ğŸš€ Quick Start with Docker

### 1. Clone and Setup

```bash
cd Docuchat
```

### 2. Configure Environment Variables

Create a `.env` file in the project root:

```env
# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=gcp-starter
PINECONE_INDEX_NAME=cricket-chatbot

# Google Gemini API
GOOGLE_API_KEY=your_google_api_key_here
```

### 3. Build and Run with Docker Compose

**Production Mode:**
```bash
docker-compose up --build
```

**Development Mode (with hot reload):**
```bash
docker-compose -f docker-compose.dev.yml up --build
```

### 4. Access the Application

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs

## ğŸ“ Project Structure

```
Docuchat/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ app.py                 # Main FastAPI application
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile            # Production Dockerfile
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ vector_store.py   # Pinecone integration
â”‚       â”œâ”€â”€ llm_chain.py      # Gemini LLM chain
â”‚       â””â”€â”€ data_loader.py    # Document processing
â”‚
â”œâ”€â”€ frontend/                  # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx           # Main app component
â”‚   â”‚   â”œâ”€â”€ App.css           # Styles
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx
â”‚   â”‚   â”‚   â””â”€â”€ KnowledgeBase.tsx
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.ts        # API client
â”‚   â”œâ”€â”€ Dockerfile            # Production Dockerfile
â”‚   â”œâ”€â”€ Dockerfile.dev        # Development Dockerfile
â”‚   â””â”€â”€ nginx.conf            # Nginx configuration
â”‚
â”œâ”€â”€ docker-compose.yml        # Production compose
â”œâ”€â”€ docker-compose.dev.yml    # Development compose
â””â”€â”€ .env                      # Environment variables
```

## ğŸ¯ Usage

### Chat Interface

1. Navigate to the **Chat** tab
2. Type your questions about uploaded documents
3. Get AI-powered responses with source citations

### Knowledge Base Management

1. Switch to the **Knowledge Base** tab
2. Upload PDF, DOCX, or TXT files
3. View all uploaded documents
4. Delete documents when needed

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/chat` | Send chat messages and get AI responses |
| `POST` | `/add_document` | Upload a document to the knowledge base |
| `DELETE` | `/delete_document/{source}` | Delete a document by source name |
| `GET` | `/list_documents` | List all documents in the knowledge base |
| `GET` | `/health` | Health check endpoint |

## ğŸ› ï¸ Development

### Running Backend Locally (without Docker)

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python app.py
```

### Running Frontend Locally (without Docker)

```bash
cd frontend
npm install
npm run dev
```

### Hot Reload in Docker

Use the development compose file for automatic code reloading:

```bash
docker-compose -f docker-compose.dev.yml up
```

## ğŸ”§ Configuration

### Backend Environment Variables

- `PINECONE_API_KEY`: Your Pinecone API key
- `PINECONE_ENVIRONMENT`: Pinecone environment (default: `gcp-starter`)
- `PINECONE_INDEX_NAME`: Index name (default: `cricket-chatbot`)
- `GOOGLE_API_KEY`: Google Gemini API key

### Frontend Environment Variables

- `VITE_API_URL`: Backend API URL (default: `http://localhost:8000`)

## ğŸ› Troubleshooting

### Pinecone Issues
- Verify your `PINECONE_API_KEY` is correct
- Check your Pinecone environment/region settings
- Ensure sufficient quota on your Pinecone account

### Gemini API Issues
- Verify your `GOOGLE_API_KEY` is correct
- Check API quota availability

### Docker Issues
- Ensure Docker and Docker Compose are installed
- Check that ports 3000 and 8000 are available
- Try rebuilding: `docker-compose up --build --force-recreate`

### CORS Issues
- Backend allows origins: `http://localhost:3000` and `http://localhost:5173`
- Update `backend/app.py` if using different ports

## ğŸ“¦ Building for Production

```bash
# Build production images
docker-compose build

# Run in detached mode
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

## ğŸ¨ Customization

### Change LLM Model

Edit `backend/src/llm_chain.py`:
```python
model = genai.GenerativeModel('gemini-2.5-flash')  # Change model here
```

### Adjust Retrieval Parameters

Edit `backend/src/vector_store.py`:
```python
results = index.query(
    vector=query_embedding,
    top_k=3,  # Change number of results
    include_metadata=True
)
```

## ğŸ“„ License

This project is open source and available for personal and educational use.

## ğŸ¤ Contributing

Feel free to submit issues, fork the repository, and create pull requests for any improvements.

## ğŸ“¸ Screenshots

![Chat Interface](https://github.com/user-attachments/assets/131e156c-c602-451f-a92c-f07a39f2f829)
![Knowledge Base](https://github.com/user-attachments/assets/65e33596-8c94-4e7e-948d-2a3d102e0999)
